<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeIn","post_body":"fadeIn","coll_header":"fadeIn","sidebar":"fadeIn"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>

  <meta name="description" content="hadoop 的文件存储系统成为 hdfs(hadoop distributed file system)，它用于解决大数据的存储问题，可以管理 分布在多台服务器中数据。">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS-hadoop的文件系统">
<meta property="og:url" content="http://example.com/2021/04/09/BigData/HDFS_conclu/index.html">
<meta property="og:site_name" content="Ha$p^3$lanet">
<meta property="og:description" content="hadoop 的文件存储系统成为 hdfs(hadoop distributed file system)，它用于解决大数据的存储问题，可以管理 分布在多台服务器中数据。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-04-09T07:18:28.000Z">
<meta property="article:modified_time" content="2021-04-09T09:21:03.972Z">
<meta property="article:author" content="Matt Yin">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2021/04/09/BigData/HDFS_conclu/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>HDFS-hadoop的文件系统 | Ha$p^3$lanet</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Ha$p^3$lanet</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Journey before Destination</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">14</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">69</span></a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">1. 概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99"><span class="nav-number">2.</span> <span class="nav-text">2. HDFS的数据读写</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-shell-%E6%93%8D%E4%BD%9C"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 shell 操作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-2-%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C"><span class="nav-number">3.</span> <span class="nav-text">2.2 客户端操作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E6%96%87%E4%BB%B6%E7%B4%A2%E5%BC%95%E7%B3%BB%E7%BB%9F"><span class="nav-number">4.</span> <span class="nav-text">3. 文件索引系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 NameNode工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-SecondaryNameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 SecondaryNameNode工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-Edit%E3%80%81FsImage-%E6%96%87%E4%BB%B6"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 Edit、FsImage 文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="nav-number">4.4.</span> <span class="nav-text">3.4 集群的安全模式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E6%95%B0%E6%8D%AE%E7%BB%93%E7%82%B9"><span class="nav-number">5.</span> <span class="nav-text">4. 数据结点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E5%8F%AF%E7%94%A8%E6%80%A7%E5%88%A4%E6%96%AD"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 可用性判断</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E6%9C%8D%E5%BD%B9%E6%96%B0%E8%8A%82%E7%82%B9%E3%80%81%E9%80%80%E5%BD%B9%E7%BB%93%E7%82%B9"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 服役新节点、退役结点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%85%B6%E4%BB%96"><span class="nav-number">6.</span> <span class="nav-text">5. 其他</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E5%AD%98%E6%A1%A3%E6%96%87%E4%BB%B6"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 存档文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-%E5%BF%AB%E7%85%A7%E7%AE%A1%E7%90%86"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 快照管理</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Matt Yin"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Matt Yin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">69</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/09/BigData/HDFS_conclu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          HDFS-hadoop的文件系统
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-04-09 15:18:28 / 修改时间：17:21:03" itemprop="dateCreated datePublished" datetime="2021-04-09T15:18:28+08:00">2021-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/04/09/BigData/HDFS_conclu/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/04/09/BigData/HDFS_conclu/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>hadoop 的文件存储系统成为 hdfs(hadoop distributed file system)，它用于解决大数据的存储问题，可以管理 分布在多台服务器中数据。 </p>
<a id="more"></a>

<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>它具有如下的 <strong>优缺点</strong>：</p>
<p>优点：</p>
<ul>
<li>多副本存储文件，具有高容错性；</li>
<li>分布式存储，适合处理大数据， 并且可将集群构建在廉价机器上。</li>
</ul>
<p>缺点：</p>
<ul>
<li>不适合低延迟的数据访问；</li>
<li>无法高效的对大量小文件进行存储（占用 NameNode 大量的内存来存储文件目录和块信息，并且小文件存储的寻址时间会超过读取时间，违反了 hdfs 的设计目标）；</li>
<li>不支持并发写入，文件随机修改。</li>
</ul>
<p>HDFS主要由下面几个部分 <strong>组成</strong>：</p>
<ul>
<li>NameNode: 充当整个集群文件系统的目录功能，存储 文件的元数据信息(metadata, 包括文件名，副本数，权限等)。此外，它还作为整个集群文件的管理者， 管理数据块的映射信息， 处理来自客户端 的读写请求等。</li>
<li>Secondary NameNode: 它并非 NameNode 的热备（就是说 NameNode 如果挂掉，它并不能马上替换 NameNode 并提供服务）。它的主要工作是辅助 NameNode的工作，包括定期合并 <code>Fsimage</code> 和 <code>Edits</code> 文件，并推送给 NameNode。在紧急情况下，可用于恢复部分 NameNode 内容。</li>
<li>DataNode: 负责实际的数据存储。</li>
<li>Client: 可请求数据读写。</li>
</ul>
<p>HDFS 数据 <strong>存储块的大小</strong> 默认为 128 M(源码中在 <code>hdfs-default.xml</code> 文件中通过参数 <code>dfs.blocksize</code>)，该值主要取决于 系统磁盘读写的速率。</p>
<p>一般地认为，寻址时间为传输时间 1% 为最佳状态，如寻址时间约为 10ms，则可计算出最佳的传输时间为约 1s。若当前磁盘传输速率普遍为 100 MB/s，一个块文件需要一次寻址，则可获得 HDFS 块的推荐大小：<code>1s * 100MB/s = 100 MB</code>，近似为 128 M。所以，如果磁盘读写速度快（如 SSD），则推荐使用更大的 HDFS 块大小。</p>
<h1 id="2-HDFS的数据读写"><a href="#2-HDFS的数据读写" class="headerlink" title="2. HDFS的数据读写"></a>2. HDFS的数据读写</h1><h2 id="2-1-shell-操作"><a href="#2-1-shell-操作" class="headerlink" title="2.1 shell 操作"></a>2.1 shell 操作</h2><p>HDFS 提供相关的指令对 文件系统中的文件进行管理（如上传、下载、删除等）。具体可以使用 <code>bin/hadoop fs 具体命令</code> or <code>bin/hdfs dfs 具体命令</code>，这两个指令差不多， <code>hadoop fs</code> 相当于是 <code>hdfs dfs</code> 的 “父类”。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -help rm # 查询 rm 指令的功能</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /  # 查看根目录下的内容</span><br><span class="line">hadoop fs -lsr /  # 递归显示 根目录下的内容</span><br><span class="line">hadoop fs -mkdir -p /user/lab1  # 穿件目录，创建多级目录需要 添加 -p</span><br><span class="line">hadoop fs -moveFromLocal $&#123;本地文件&#125; $&#123;hdfs目录&#125;   # 剪切文件</span><br><span class="line">hadoop fs -copyFromLocal $&#123;本地文件&#125; $&#123;hdfs目录&#125;   # 复制文件 -- 或者使用 -put</span><br><span class="line">hadoop fs -copyToLocal $&#123;hdfs文件&#125; $&#123;本地目录&#125;      # 从 hdfs 中下载文件到本地，或者使用 -get</span><br><span class="line">hadoop fs -appendToFile $&#123;追加的文件&#125; $&#123;hdfs中的文件目录&#125;</span><br><span class="line"></span><br><span class="line">hadoop fs -chgrp $&#123;组名&#125;   # 修改组</span><br><span class="line"></span><br><span class="line">hadoop fs -cp $&#123;hdfs中原文件&#125; $&#123;hdfs中目的地址&#125;  # 拷贝</span><br><span class="line">hadoop fs -mv $&#123;hdfs中原文件&#125; $&#123;hdfs中目的地址&#125;  # 剪切</span><br><span class="line">hadoop fs -getmerge $&#123;待合并的文件内容&#125; $&#123;合并后的文件名&#125;  # 合并文件</span><br><span class="line"></span><br><span class="line">hadoop fs -tail $&#123;文件名&#125;  # 查看文件的最后一些行 -- log 文件常常以追加的形式更新，所以这个很常用</span><br><span class="line">hadoop fs -rm $&#123;文件名/文件夹&#125;  # 删除文件、文件夹， -R 参数，递归删除。</span><br><span class="line">hadoop fs -du $&#123;目录&#125;       # 查询对应目录的内容的大小，添加 -h 参数，添加单位例如 M；-s 参数，统计整个文件夹总大小</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 副本设置</span></span><br><span class="line">hadoop fs -setrep $&#123;副本数&#125; $&#123;文件名&#125;</span><br></pre></td></tr></table></figure>

<p>整体来说，hdfs 的操作指令与 linux 文件的操作非常类似。</p>
<h1 id="2-2-客户端操作"><a href="#2-2-客户端操作" class="headerlink" title="2.2 客户端操作"></a>2.2 客户端操作</h1><p>可以在 windows 上建立客户端，然后通过 java 程序来操作 hdfs 的文件。首先需要在 windows 上搭建 hadoop 环境，参考 <a target="_blank" rel="noopener" href="https://smallgreens.github.io/2021/02/02/BigData/InstallOnWindows/">link</a>。</p>
<p>配置完毕后，可以使用 intellij 新建一个 maven 工程，具体可以参考 github 中的 <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/blob/main/src/main/java/HDFSClient.java">代码</a>。</p>
<p>使用客户端可以进行对 hdfs 进行读写。其中 <strong>写数据</strong> 步骤如下：</p>
<ol>
<li>客户端创建 distributed <code>FileSystem</code> 对象（含有上传到 hdfs 系统中的路径信息），向 <strong>NameNode</strong> 所在的服务器发送上传请求；</li>
<li>NameNode 检查文件路径等信息，进行一些检查：例如文件是否存在，路径是否合法等。检查完毕后响应客户端的请求；</li>
<li>客户端得到可以上传的响应信息后，请求上传第一个 block；</li>
<li>NameNode 收到该请求后进行分析，返回给客户端上传数据的 <strong>DataNode</strong>，e.g. dn1, dn2, dn3。数据结点的确定主要根据<strong>两个因素</strong>：1. 距离近的有限上传；2. 负载轻的优先上传；</li>
<li>客户端生成输出流 <code>FSDataOutputStream</code>，向对应的 DataNode 请求建立 block 的传输通道；</li>
<li>DataNode 应答成功，客户端进行数据传输（一个个的 packets）；</li>
<li>DataNode 服务器中首先将数据放置在内存中，一边序列化到本地硬盘，一边传输到下个结点的内存中。</li>
</ol>
<p>在上面的第四步中，NameNode 需要寻找存储数据的结点，这一结点的确定遵循距离最近的原则，即上传数据的结点与存储数据的结点距离尽可能近。这里，就需要定义 <strong>结点距离</strong>：为两个结点到达最近的公共祖先的距离总和。例如：</p>
<ul>
<li>同一结点上的进程：距离 = 0；</li>
<li>同一机架上的不同结点（共一个端结点）：距离 = 2；</li>
<li>同一数据中心不同机架上的结点（同一数据中心的机架端结点接到同一个数据中心结点上）：距离 = 4。</li>
</ul>
<p>除了上述的距离最近原则，具体存储数据时 hadoop 还需考虑数据的安全可靠。对于常见的 3副本设置（<a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication">参考官网</a>），数据的放置一般首先放置在某一随机的结点（尽量考虑距离近，负载均衡），然后第二个副本放置在同一机架的不同 结点上，而第三个副本则放置在不同的机架上（为了<strong>安全可靠性</strong>）。</p>
<p>类似于写数据，<strong>读数据</strong>也需要客户端首先与 NameNode 进行通讯，然后再从具体的 DataNode 上读取数据。步骤如下：</p>
<ol>
<li>客户端创建 distributed <code>FileSystem</code> 对象（包含 hdfs 文件目录信息），向 NameNode 发送下载请求；</li>
<li>NameNode 返回目标文件的元数据，客户端获得数据存在的 DataNode 位置；</li>
<li>客户端创建 <code>FSDataInputStream</code> 对象，并逐块向对应的 DataNode 结点请求数据（如果多块文件在同一个服务器上，可以一次性返回）；</li>
<li>获取完毕数据后本地拼接为完整文件。</li>
</ol>
<h1 id="3-文件索引系统"><a href="#3-文件索引系统" class="headerlink" title="3. 文件索引系统"></a>3. 文件索引系统</h1><p><strong>NameNode</strong> 和 <strong>SecondaryNameNode</strong> 共同构成了 HDFS 的文件索引、管理系统。这里对他们的工作机制进行详细的介绍。</p>
<h2 id="3-1-NameNode工作机制"><a href="#3-1-NameNode工作机制" class="headerlink" title="3.1 NameNode工作机制"></a>3.1 NameNode工作机制</h2><p>在运行的 HDFS 系统中，NameNode 为实现运行的高效，总是在内存中运行。但内存具有掉电丢失的特点，为了保证数据的可靠性，HDFS 会在在磁盘中使用 <code>FsImage</code> 备份元数据（所谓元数据就是文件属性信息，比如修改日期，权限等）。</p>
<p>但频繁操作存储于磁盘中的数据，会降低系统性能。因此，为减少 <code>FsImage</code> 的修改，当需要更新 元数据时，会 <strong>首先</strong> 将更新的内容记录到 <code>Edits</code> 文件（也在磁盘中，但只进行追加操作，效率非常高），然后 再在 内存中更新（安全性）。</p>
<p>当 <code>NameNode</code> 服务器上电时，它将编辑日志（<code>edits_inprogress_xxx</code>）和 镜像文件(<code>Fsimage</code>) 加载到内存中，进行合并，恢复出整个集群的元数据信息 (通常内存至少128 G, 每个 block 占 150 bytes)。</p>
<h2 id="3-2-SecondaryNameNode工作机制"><a href="#3-2-SecondaryNameNode工作机制" class="headerlink" title="3.2 SecondaryNameNode工作机制"></a>3.2 SecondaryNameNode工作机制</h2><p>由于 <code>Edits</code>文件 不能无限扩大，再它达到一定大小时，需要与 <code>FsImage</code> 文件进行合并。HDFS 使用 SecondaryNameNode，来实现这一功能。具体地，在 SecondaryNameNode 中，会按顺序执行下列操作：</p>
<ol>
<li>请求询问 NameNode 是否需要进行 checkpoint 操作 （即日志和镜像文件合并），当下列两个任一个满足时，会触发 checkpoint：<ol>
<li>定时时间到（默认是1小时，<code>hdfs-site.xml</code> 中配置 property <code>dfs.NameNode.checkpoint.period</code> 修改）</li>
<li>Edits 中的数据条数超过阈值（以轮询方式查询，默认每隔1分钟轮询一次，默认阈值是100万条，<code>hdfs-site.xml</code> 中， <code>dfs.NameNode.checkpoint.txns</code> 配置阈值， <code>dfs.NameNode.checkpoint.check.period</code> 配置轮询时间间隔）；</li>
</ol>
</li>
<li>如果需要 checkpoint 操作，首先将 NameNode 中的 <code>edit_inprogress_001</code> 文件滚动为 <code>edits_001</code> 并同时生成 空的 <code>edit_inprogress_002</code> 文件，后序修改记录将会添加到 <code>edit_inprogress_002</code> 中。</li>
<li>然后将 <code>edit_001</code> 和 <code>FsImage</code> 文件拷贝到 SecondaryNameNode 中，SecondaryNameNode 在内存中将上述两者进行合并，生成新的 <code>FsImage</code> 文件。</li>
<li>最后将合并生成的新的 <code>FsImage</code> 文件拷贝回 NameNode 中，替换旧的 <code>Fsimage</code> 文件。</li>
</ol>
<h2 id="3-3-Edit、FsImage-文件"><a href="#3-3-Edit、FsImage-文件" class="headerlink" title="3.3 Edit、FsImage 文件"></a>3.3 Edit、FsImage 文件</h2><p>在 NameNode 服务器上，<code>Edit</code> 和 <code>FsImage</code> 文件在 目录 <code>hadoop-2.8.3/data/tmp/dfs/name/current</code> 中。可以使用 <code>hdfs oiv -p XML -i &lt;要转换的fsimage 文件名&gt; -o &lt;输出的文件名.xml&gt;</code> 将 FsImage 转为 xml 文件进行展示。可以看到，在 fsimage 文件中，存放了文件的 <strong>文件名</strong>，<strong>路径</strong>，<strong>副本数</strong>，<strong>权限</strong>，<strong>创建时间</strong> 等 meta 信息。类似的，可以使用 <code>hdfs oev -p XML -i &lt;要转换的 edits 文件&gt; -o &lt;输出的文件名.xml&gt;</code> 将 <code>Edits</code> 文件转为 xml 格式进行查看。</p>
<p>需要注意的是，<code>FsImage</code> 文件和 <code>Edits</code> 文件 并没有记录 块所对应的 DataNode。在 HDFS 中，这一信息 （DataNode 上的数据块信息） 将会在在集群启动后 由各个 <strong>DataNode</strong> 进行 <strong>动态上报</strong>。具体地，在集群启动时，所有 DataNode 会上报一次他们所持有的数据块信息，然后，后序每隔一段时间 DataNode 会再进行上报。这么做是因为数据块的位置信息可能会因为 DataNode 的状态而变化，因此使用动态的方式获取，保证数据位置信息的准确性和实时性。</p>
<h2 id="3-4-集群的安全模式"><a href="#3-4-集群的安全模式" class="headerlink" title="3.4 集群的安全模式"></a>3.4 集群的安全模式</h2><p>根据上述的介绍，我们知道了 HDFS 文件索引系统保存更新索引的方式。在这样的机制下，HDFS 系统在 NameNode 启动时，会有一段特殊的安全模式期。</p>
<p>所谓的 <strong>安全模式</strong> 是指 NameNode 文件索引系统对于客户端来说是只读的，不允许执行写操作。当 HDFS 系统启动，便处于安全模式。</p>
<p><strong>NameNode</strong> 首先将镜像文件 <code>FsImage</code> 载入内存，并执行编辑日志（<code>Edits</code>） 中的各项操作。合并完成后，创建一个新的 <code>FsImage</code> 文件和一个空的 编辑日志放回磁盘，同时，NameNode 会开始监听 DataNode 的请求。</p>
<p>对于各个 <strong>DataNode</strong>，他们以块列表的形式记录 各个存储在它们上的数据块。在系统正常操作期间， NameNode 会在内存中保留所有块的位置映射信息。但在 DataNode 和 NameNode 启动时，需由 DataNode 向 NameNode 发送最新的块列表信息。</p>
<p>最后，当 NameNode 完成 FsImage 的 <strong>合并操作</strong>，并且接收到 <strong>足够多的块位置信息</strong> 后，才会退出安全模式（达到最小副本条件后30s 退出安全模式）。</p>
<p>所谓 <strong>最小副本条件</strong> 是指： 整个文件系统中 99.9% 的块满足最小副本级别的要求（默认值：<code>dfs.replication.min=1</code>）。</p>
<p>最后，在刚刚格式化一个 hdfs 集群的时候，由于系统中还没有任何块，NameNode 不会进入安全模式。</p>
<h1 id="4-数据结点"><a href="#4-数据结点" class="headerlink" title="4. 数据结点"></a>4. 数据结点</h1><p>DataNode 中存放一个个的 blocks, 数据 block 的内容包括：数据，数据长度，校验和，时间戳。通过上面对 NameNode 的介绍，我们知道数据的存储信息仅放置在 NameNode 内存中（即不做持久化处理），需要 DataNode 进行动态的上报、更新。</p>
<p>具体的，块信息分为 <strong>启动时</strong> 上报和 <strong>运行中</strong> 的上报。启动时，DataNode 启动后向 NameNode 注册，报告其中的块信息，注册成功后，NameNode 向 DataNode 返回注册成功信息。运行中， DataNode 会每隔固定时间（1小时）上报一次所有块信息。</p>
<h2 id="4-1-可用性判断"><a href="#4-1-可用性判断" class="headerlink" title="4.1 可用性判断"></a>4.1 可用性判断</h2><p>除了数据块信息的上报，NameNode 需要知道 DataNode 的 <strong>可用性</strong>，即判断相关的 DataNode 网络是否顺畅连通，硬件是否运行正常。这一目标由 DataNode 和 NameNode 之间保持的 <strong>心跳通讯</strong> 来实现。DataNode 心跳每3秒1次，心跳返回结果带有 NameNode 给该 DataNode 的命令。</p>
<p>通常，如果超过 10 分钟（+30s）没有收到 DataNode 的心跳，NameNode 会认为该结点不可用，从而以后不会再向该 DataNode 中存放任何内容。</p>
<p>上述的 DataNode 的延迟下线时间称为 <strong>超时时长</strong>。hdfs 默认的超时时长 10分钟 + 30 秒 通过公式 <code>timeout = 2 * dfs.NameNode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval</code> 计算。其中 <code>dfs.NameNode.heartbeat.recheck-interval</code> 默认值为 5分钟（300’00 ms），<code>dfs.heartbeat.interval</code> 默认值为 3秒。</p>
<h2 id="4-2-服役新节点、退役结点"><a href="#4-2-服役新节点、退役结点" class="headerlink" title="4.2 服役新节点、退役结点"></a>4.2 服役新节点、退役结点</h2><p>如果想向集群中添加新的 datanode，只需要镜像集群中的一台 datanode 机器，修改 ip 和主机名称，并删除其中的旧数据 和 旧 logs: <code>rm -rf /data /logs</code>。最后在新的结点上单独启动 DataNode 以及 nodemanager，即可自动并入集群中。</p>
<p>如果想提升安全性，仅让有权限的机器加入到集群中，可以使用 <strong>“白名单”</strong> 功能（<code>hdfs-site.xml</code> 中添加 <code>dfs.hosts</code> 属性）。此外，还可以使用黑名单方式，强制集群中的某些服务器退出（退出结点上的内容会被拷贝到其他节点上）。</p>
<h1 id="5-其他"><a href="#5-其他" class="headerlink" title="5. 其他"></a>5. 其他</h1><h2 id="5-1-存档文件"><a href="#5-1-存档文件" class="headerlink" title="5.1 存档文件"></a>5.1 存档文件</h2><p>小文件会影响 hdfs 系统的性能。因为每个小文件都占用一个文件块，而每个文件块都需要在 NameNode 中占有一条记录，故每个小文件都会占用 150 字节的记录空间（注意：不影响DataNode，数据实际存储空间仍是文件大小）。因此，有大量小文件时，会大量占用 NameNode 中的索引资源。</p>
<p>一种处理方案是 使用 hdfs 存档文件 或称 har 文件。原理上，hdfs 存档文件对内是一个个独立文件，但是对 NameNode 而言却是一个整体，因为减少了在 NameNode 中内存的占用。 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archivename &lt;归档后的名字-.har 结尾&gt; -p &lt;src文件的路径&gt; &lt;输出文件的路径&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以查看 har 存档文件，相当于一个单独的文件系统</span></span><br><span class="line">hadoop fs -ls -R har://&lt;har 文件路径&gt; </span><br></pre></td></tr></table></figure>

<h2 id="5-2-快照管理"><a href="#5-2-快照管理" class="headerlink" title="5.2 快照管理"></a>5.2 快照管理</h2><p>HDFS 支持快照备份。但 HDFS 快照并不会立即复制所有的文件，在产生快照时，仅对目录做一个复制备份，只有当后序有写入、修改发生时，才会产生新的文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开启指定目录的快照功能</span></span><br><span class="line">hdfs dfsadmin -allowSnapshot &lt;路径&gt;  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 对目录创建快照</span></span><br><span class="line">hdfs dfs -createSnapshot &lt;路径&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 比较两个快照目录的不同之处  </span></span><br><span class="line">hdfs snapshotDiff &lt;路径1&gt; &lt;路径2&gt;  </span><br></pre></td></tr></table></figure>

<p><strong>参考</strong></p>
<ol>
<li>尚硅谷Hadoop 2.x教程(hadoop框架精讲)：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cW411r7c5">https://www.bilibili.com/video/BV1cW411r7c5</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/03/31/Database/B_tree/" rel="prev" title="数据库索引方式">
                  <i class="fa fa-chevron-left"></i> 数据库索引方式
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/04/09/BigData/MapReduce_conclu/" rel="next" title="MapReduce-hadoop的计算框架">
                  MapReduce-hadoop的计算框架 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Matt Yin</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments('#valine-comments', () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', () => {
    new Valine(Object.assign({"enable":true,"appId":"k2sEIOb3zYiWCB2PDVhHsp1y-MdYXbMMI","appKey":"kgxrBrtFbe83dXfCFnYkplkY","serverURLs":null,"placeholder":"欢迎留言~","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":false,"comment_count":false,"recordIP":false,"enableQQ":false,"requiredFields":[]}, {
      el: '#valine-comments',
      path: "/2021/04/09/BigData/HDFS_conclu/",
      serverURLs: "https://k2seiob3.api.lncldglobal.com"
    }));
  }, window.Valine);
});
</script>

</body>
</html>
