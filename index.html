<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeIn","post_body":"fadeIn","coll_header":"fadeIn","sidebar":"fadeIn"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Ha$p^3$lanet">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Ha$p^3$lanet">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Matt Yin">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Ha$p^3$lanet</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Ha$p^3$lanet</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Journey before Destination</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">25</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">13</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">63</span></a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Matt Yin"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Matt Yin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">63</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">
      

      
    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/09/BigData/MapReduce_conclu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/09/BigData/MapReduce_conclu/" class="post-title-link" itemprop="url">MapReduce-hadoop的计算框架</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-04-09 17:18:28 / 修改时间：17:12:47" itemprop="dateCreated datePublished" datetime="2021-04-09T17:18:28+08:00">2021-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>MapReduce 是一个分布式运算程序的编程框架，是用户开发 “基于hadoop 的数据分析应用” 的核心框架。</p>
<p>MapReduce 核心功能是将 <strong>用户编写的业务逻辑代码</strong> 和 <strong>自带默认组件</strong> 整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</p>
<h2 id="1-1-优缺点"><a href="#1-1-优缺点" class="headerlink" title="1.1 优缺点"></a>1.1 优缺点</h2><p>在项目技术选型阶段，我们需要根据各个技术的优缺点选择最匹配项目需求的技术实现路线。因此，这里总结 MapReduce 的优缺点如下：</p>
<ul>
<li>优点：<ul>
<li>易于编程，它简单的实现了一些接口，就可以完成一个分布式程序；</li>
<li>良好的扩展性；</li>
<li>高容错性，可以将运行失败的任务自动转移到另外结点上运行；</li>
<li>适合 <strong>PB</strong> 级以上海量数据的 <strong>离线处理</strong>。</li>
</ul>
</li>
<li>缺点：<ul>
<li>不擅长实时计算，无法像MySQL一样在毫秒或者秒级内返回结果；</li>
<li>不擅长流式计算，流式计算的输入数据是动态的，而 MapReduce 输入数据集必须是静态的，不能动态变化。</li>
<li>不擅长 DAG(有向图) 计算，DAG即多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。因为 MapReduce 作业的结果都会写入磁盘，因此面对这种操作会造成大量的磁盘 IO，从而导致性能低下。</li>
</ul>
</li>
</ul>
<h2 id="1-2-构成"><a href="#1-2-构成" class="headerlink" title="1.2 构成"></a>1.2 构成</h2><p><strong>MapReduce</strong> 可以分为两个阶段：Map 阶段和 reduce 阶段，这两个阶段的程序任务分别称为 MapTask 和 ReduceTask。每一个阶段的task 都以并行方式运行，但两个 task 阶段为串行执行，即 reduce 阶段的task 需要等待 map 阶段的task 执行完毕后才能执行。</p>
<p>一个 MapReduce 程序由下面3个部分组成：</p>
<ul>
<li>MrAppMaster: 负责整个任务程序的过程调度即状态协调，相当于是整个任务的老大；</li>
<li>MapTask: 负责 map 阶段的整个数据处理流程。</li>
<li>ReduceTask：负责 reduce 阶段整个数据处理流程。</li>
</ul>
<p><strong>MapReduce编程规范</strong>：编写的程序分为 mapper, reducer, driver 三个部分。分别是对 MapTask, ReduceTask 的实现，以及对整个MapReduce程序的配置。</p>
<p><strong>在集群上运行</strong>：MapReduce 程序可以在本地运行，也可以打包成 jar 包，上传至集群，然后运行。打包工作可以利用 maven 来实现，具体的，是在 <code>pom.xml</code> 中进行配置，添加 <code>&lt;build&gt;</code> 部分的 相关的 plugin，并写入相关的编译设置（具体参考 github 中的 <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/blob/main/pom.xml">POM文件</a>）。括号中链接的例子是以 wordCount 程序为例，导出 jar 文件后，将其命名为 <code>wc.jar</code> 并上传至服务器中，最后可以在服务器中使用下面的指令运行程序：<code>hadoop jar wc.jar WordCountDriver /user/lab1/input /user/lab1/output</code>。</p>
<h2 id="1-3-序列化"><a href="#1-3-序列化" class="headerlink" title="1.3 序列化"></a>1.3 序列化</h2><p>序列化是指将内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。类似的，磁盘的内容读取为内存中对象，称为反序列化。</p>
<p>需要注意的是，Hadoop 单独提供了一套序列化方案，而不是直接使用 Java 的序列化 （<code>Serializable</code>，所有的包装类都实现了 该接口）。原因是，Java 的序列化框架过重，一个对象被序列化后，会附带很多额外的信息（校验信息，header，继承体系等），不利于网络传输。所以 hadoop提供了一套自己的序列化机制（<code>Writable</code>）。</p>
<p>类似于 Java 中的 <code>Serializable</code> 接口，<code>Writable</code> 接口定义了 Hadoop 中的序列化方式。对于基本数据类型，Hadoop 提供一套自己的封装类，全部实现 <code>Writable</code> 接口，包括 <code>LongWritable(Long), IntWritable(Integer), Text(String)...</code> （Note: 除 <code>String</code> 外，各类型对象名就是在原数据类型后添加 <code>Writable</code>）。</p>
<p>除了使用框架中提供的可序列化对象，通过实现 <code>Writable</code> 接口并重写 <code>write()</code> 和 <code>readFields()</code> 方法，我们可以实现自定义的序列化对象。<a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/blob/main/src/main/java/flowSum/FlowBean.java">例子参考</a>。</p>
<h1 id="2-MapReduce-框架原理"><a href="#2-MapReduce-框架原理" class="headerlink" title="2. MapReduce 框架原理"></a>2. MapReduce 框架原理</h1><p>整个 MapReduce 程序的流程如下面两张图所示。</p>
<p><img src="mapreduce_workFlow.jpg" alt="MapReduce工作流程1"></p>
<p><img src="mapreduce_workFlow2.jpg" alt="MapReduce工作流程2"></p>
<p>下面我们就根据整个 MapReduce 程序执行的流程对各个部分进行更加细节的分析。</p>
<h2 id="2-1-Job-提交与切片计算"><a href="#2-1-Job-提交与切片计算" class="headerlink" title="2.1 Job 提交与切片计算"></a>2.1 Job 提交与切片计算</h2><p>在程序代码中，Driver 部分获取 Job 对象，进行一系列的设置之后，会 <code>submit</code> 该 job。提交的信息主要包括三个部分：<strong>切片信息</strong>、<strong>jar包</strong>、<strong>xml 文件</strong>。</p>
<p><strong>xml文件</strong> 主要是程序执行的相关设置，<strong>jar包</strong> 则为map 程序和 reduce 程序的具体计算逻辑以及程序所用到的相关依赖组件。<strong>切片信息</strong> 相对来说最为关键，在 MapReduce 计算框架中，分片的数量，决定了并行的 MapTask 的数量，即每个 split 切片会分配一个 MapTask 来处理。</p>
<p>在这里，需要区分 切片(split)和数据块(block) 两个概念。Block 是实际的物理存储块，在 <code>hdfs-site.xml</code> 中可以对该值进行设定，通常默认为 128 M。而 split 则是 <code>MapReduce</code> 计算框架中的一个虚拟的切分量，它 <strong>与物理的存储无关</strong>。</p>
<p>当然，在 Hadoop 的默认设置中，split 的大小等于 block 的大小，这是由于同一个文件的不同 block 可能位于不同的服务器上，如果设置 split 大小与 block 不相等，可能会导致同一个 MapTask 需要从不同的服务器上获取数据，会导致系统效率降低。</p>
<p>具体地，切片过程中，默认切片方法为：</p>
<ol>
<li>每个单独的文件做一个切片；</li>
<li>如果文件大于 block size，则 默认以块大小为切片大小进行切片（本地模式默认切片大小为32M）；</li>
<li>如果一个文件多次切片后剩余大小小于 1.1 倍 (SPLIT_SLOP) 的块大小，则不再切片（减少小文件）。</li>
</ol>
<p>实际中，也可按需要自定义切片大小<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/9678180/change-file-split-size-in-hadoop">参考1</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/yljphp/article/details/89070948">参考2</a>。</p>
<p><strong>小文件处理</strong>：由于默认每个单独的文件至少形成一个切片，对于有大量小文件的情况，会产生过多的小切片，从而产生大量的 MapTask，使得系统的处理效率降低。一种处理方案是使用 <code>CombineTextInputFormat</code>作为 <code>InputFormat</code> （<a target="_blank" rel="noopener" href="https://www.kancloud.cn/java-jdxia/java/746893">参考</a>）。</p>
<h2 id="2-2-FileInputFormat"><a href="#2-2-FileInputFormat" class="headerlink" title="2.2 FileInputFormat"></a>2.2 FileInputFormat</h2><p>MapReduce 框架在提交 job 之后，根据 split 数启动对应数量的 MapTask, 并开始对对应分片的数据进行处理。这一处理阶段主要是进行数据读取，将原始数据读取为特定的 Java 对象，并进行响应的数据处理。</p>
<p>如何从文件数据中读取内容，MapReduce 框架通过实现了 <code>FileInputFormat</code> 接口的类进行规定（在 Driver 中进行设置）。这一接口规定了 数据的读取格式：即将文件中的数据以何种 <strong>键值对</strong> 的形式读取到程序内存中。例举 Hadoop 中提供的实现类如：</p>
<ul>
<li><code>TextInputFormat</code>：它是默认的 <code>FileInputFormat</code> 的实现类。它按行读取文件中的数据。<strong>键值</strong> 为当前读取的行在文件中的偏移量（字节为单位，<code>LongWritable</code> 类型），<strong>值</strong> 则是一行数据的内容（不包括任何终止符，即换行符和回车符），为 <code>Text</code> 类型；</li>
<li><code>keyValueTextInputFormat</code>: 与 <code>TextInputFormat</code> 相同，将每一行数据作为一条记录。但 键、值 均为这一行的内容，具体的，是通过分隔符进行分割，分隔符前面的为 <strong>key</strong>，后面的为 <strong>value</strong>。 默认分隔符为 tab (<code>\t</code>)， 可以通过 <code>conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, &quot; &quot;);</code> 来改变分隔符。</li>
</ul>
<p>如果系统提供的 <code>FileInputFormat</code> 实现类不能满足我们的需求，我们还可以通过自己实现该接口，自定义从文件到 MapTask 输入值的映射关系，具体参考 <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/InputFormat">例子代码</a>。</p>
<p><strong>Note</strong>:InputFormat 实际上可以规定切片策略 和 读取时映射 key-value 方式。读取时映射 key-value 的方式主要通过 <code>CreateRecordReader()</code> 方法中返回的 <code>RecordReader</code> 对象决定（<a target="_blank" rel="noopener" href="https://www.cnblogs.com/sunbr/p/13330622.html">参考</a>）。</p>
<h2 id="2-3-Shuffle-阶段"><a href="#2-3-Shuffle-阶段" class="headerlink" title="2.3 Shuffle 阶段"></a>2.3 Shuffle 阶段</h2><p>MapTask 处理完毕的数据会经过 OutputCollector 进入到 shuffle 阶段。具体地，数据会进入一个环形缓冲区（equator 的一侧放置 meta 信息，另一侧放置 kv 数据），当数据达到一定量后，会溢写到 container 或者磁盘（<a target="_blank" rel="noopener" href="http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--%E7%8E%AF%E5%BD%A2%E7%BC%93%E5%86%B2%E5%8C%BA.html">参考</a>）。</p>
<p>在 Shuffle 阶段，最核心的几项任务包括 分区（partition），排序（Sorting），合并（Combiner）。下面对这几项任务重点介绍。</p>
<h3 id="a-分区"><a href="#a-分区" class="headerlink" title="a. 分区"></a>a. 分区</h3><p>在 Hadoop 中，我们可以通过自定义 <strong>分区方式</strong>，将同一类型的数据放置到同一个分区中，再分别交由不同的 ReduceTask 进行并行处理。</p>
<p>系统默认分区在 <code>HashPartitioner</code> 类 (继承了 <code>Partitioner</code> 类) 中通过 <code>getPartition()</code> 函数进行规定，计算方法为 <code>(key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</code>。默认情况下，<code>numReduceTasks</code> 的值为1，因此，默认所有的 MapTask 输出的结果会放置到同一个分区下，最终交给一个 ReduceTask 来处理。</p>
<p>自定义 partitioner 的方法可以看<a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/flowSum">参考例子</a>。</p>
<p>需要注意的是，在自定义分区方式的同时，一定要在 driver 类中将 job 的 ReduceTask 数量设置为与 分区数量相匹配的值。如果不匹配，可能会发生下列问题：</p>
<ul>
<li>如果 reducetask 数量大于 getPartition 的结果数，则会产生几个空的输出文件；</li>
<li>如果 reducetask 数量小于 getPartition 的结果数，则有一部分数据无处放置，报 exception；</li>
<li>如果 reducetask 数量为1，所有数据都放置到一个文件中，无论 在 getPartition 中设置了多少个分区。</li>
</ul>
<h3 id="b-排序"><a href="#b-排序" class="headerlink" title="b. 排序"></a>b. 排序</h3><p>在 MapReduce 的计算框架中，会根据数据的 key 值进行多次排序。第一次排序是在环形缓冲区中（准备溢写时）使用 <strong>快速排序法</strong> 进行首次排序，接下来的几次排序则是对初步 有序的数据进行进一步排序，使用 <strong>归并排序法</strong>。 </p>
<p>通常，具体的排序策略并不需要我们处理，我们只需要规定判定数据之间大小关系的规则即可。具体地，我们可以通过自定义 MapTask 的输出 k-v 对的 key 值的 <code>compareTo</code> 方法，来实现这一目标。可查看 参考示例代码：<a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/blob/main/src/main/java/sort">参考1</a>， <a href="%E5%A4%9A%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F%EF%BC%9Ahttps://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/order">参考2</a>。</p>
<h3 id="c-Combiner"><a href="#c-Combiner" class="headerlink" title="c. Combiner"></a>c. Combiner</h3><p>Combiner 是 MR 程序中 Mapper 和 Reducer 之外的一种组件，它是 Reducer 的子类，因此，功能与 Reducer 非常类似。不同点是，二者的运行位置不同： combiner 是在每一个 MapTask 所在的节点运行；而 Reducer 是接收全局所有 Mapper 的输出结果。</p>
<p>可以想到，Combiner 的意义就是对每个 MapTask 的输出进行局部汇总，从而可以减小网络传输量。</p>
<p>需要注意的是，Combiner 能够应用的前提是不影响最终的业务逻辑（适合各种求和，汇总场景，不适用于求平均等涉及除法场景）。并且，Combiner 输出的 kv 应该跟 Reducer 输入 kv 类型对应起来。</p>
<h2 id="2-4-Reduce-阶段"><a href="#2-4-Reduce-阶段" class="headerlink" title="2.4 Reduce 阶段"></a>2.4 Reduce 阶段</h2><p>数据经过 shuffle 过程之后，会最终进入到 reduce 阶段。系统根据分区数（driver 类中需进行设置）启动 reducetask。系统会将将所有 maptask 中相同分区的数据放到同一个 ReduceTask。数据进来后，再进行 归并排序，合并。reduce 逻辑处理完毕后，通过<code>context.write(k, v)</code> 写出，最终系统会根据指定的 <code>outputFormat</code> 将数据最终写出到文件。 </p>
<p>总结来说，reduce 分为下面三个过程：</p>
<ul>
<li>copy 阶段，拷贝对应数据到 reduceTask 所在的本地磁盘。</li>
<li>merge，sort 阶段：数据溢写到硬盘，将数据排序，分组。</li>
<li>reduce 阶段：相同组的到同一个 reduce 中。</li>
</ul>
<h3 id="a-ReduceTask-并行度"><a href="#a-ReduceTask-并行度" class="headerlink" title="a. ReduceTask 并行度"></a>a. ReduceTask 并行度</h3><p>如前面所述，ReduceTask 并行度需要与分区情况进行匹配，方可达到最佳效果。具体 reduceTask 的数量可以在 driver 类中设定：<code>job.setNumReduceTasks(&#39;并行数&#39;)</code>。</p>
<p>关于 reduce Task 数量的相关的注意点总结如下：</p>
<ol>
<li>reduceTask = 0, 表示没有 reduce 阶段，输出文件个数和 map 个数一致；</li>
<li>reduceTask 默认值为 1， 所以输出文件个数为1个。ReduceTask 数量并不是随意设置的，需要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有一个 reduceTask。</li>
<li>如果数据分布不均匀，就有可能在 reduce 阶段产生数据倾斜，需要避免！</li>
<li>具体开多少个 reducetask 最好，还由集群性能决定；</li>
<li>如果分区数不是 1，但是 reduceTask 为 1，则实际不执行分区过程。因为在 maptask 源码中，执行分区之前，会先判断reduceNum 的个数是否大于1，不大于 1 则不执行任务。</li>
</ol>
<h3 id="b-OutputFormat-接口"><a href="#b-OutputFormat-接口" class="headerlink" title="b. OutputFormat 接口"></a>b. OutputFormat 接口</h3><p>类似 <code>InputFormat</code> 可以规定文件读取时的切片方式和 输入 Map Task 的 key-value 的模式， <code>OutputFormat</code> 则规定了 MapReduce 程序输出内容的形式。Hadoop 默认的 <code>OutputFormat</code> 是 <code>TextOutputFormat</code>，当需要使用多级 MR 时， 可以使用 <code>SequenceFileOutputFormat</code>。</p>
<p>可以通过自定义的输出格式(继承<code>FileOutputFormat</code>)，实现数据直接输入数据库等功能。</p>
<p>具体可以参考 <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/outputFormat">案例</a>。</p>
<h1 id="3-案例及调试"><a href="#3-案例及调试" class="headerlink" title="3. 案例及调试"></a>3. 案例及调试</h1><h2 id="3-1-案例：Join的多种应用"><a href="#3-1-案例：Join的多种应用" class="headerlink" title="3.1 案例：Join的多种应用"></a>3.1 案例：Join的多种应用</h2><p>JOIN 即数据的合并，是数据库中经常需要进行的操作，但对于 MapReduce 程序，如何实现大数据的 JOIN 呢？通常有两种方案。</p>
<p><strong>方案1</strong>: reduce join</p>
<p>reduce join 是通过在 map 阶段对数据进行标记，然后在 reduce 阶段统一进行合并。具体过程如下。</p>
<p>Map端：为来自不同表（或文件） 的 key/value 对，打标签以区别不同的来源记录。然后用连接字段作为 key（连接字段是join 使用的字段），其余部分和新加的数据来源标签作为 value，最后进行输出。</p>
<p>Reduce 端：以连接字段作为 key 的分组已经完成，只需要在每个分组中将 来源于不同文件的记录分开，最后进行合并即可。</p>
<p>参考代码：<a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/tableJoin">https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/tableJoin</a></p>
<p>Reduce join 的缺点：合并操作在 reduce 阶段进行，reduce 端的处理压力太大，map 结点运算负载低，资源利用率不高，且在 reduce 阶段极易产生数据倾斜。</p>
<p><strong>方案2</strong>：map join</p>
<p>为解决在 reduce 端合并的问题，可以考虑在 map 端对数据进行合并。方法是先将数据量较小的表预缓存到内存中，然后再读取另外的表，同时进行合并操作。通常适用于一张大表 + 1张很小的表的情况。</p>
<p>参考代码: <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/cache">https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/cache</a></p>
<h2 id="3-2-调试方法：计数器"><a href="#3-2-调试方法：计数器" class="headerlink" title="3.2 调试方法：计数器"></a>3.2 调试方法：计数器</h2><p>单线程的程序可以使用 debug 来处理， 但是多线程的程序，则通常需要通过计数器、log 等工具来实现调试。</p>
<p>hadoop 为每个作业维护若干内置计数器。例如有记录处理的字节数的计数器，可以监控已处理的输入数据量和已产生的输出数据量。</p>
<p>默认的 mapreduce 框架中就有很多的计数器， 在控制台的输出可以看到：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Map input records&#x3D;6</span><br><span class="line">Map output records&#x3D;6</span><br><span class="line">Input split bytes&#x3D;95</span><br><span class="line">Spilled Records&#x3D;0</span><br><span class="line">Failed Shuffles&#x3D;0</span><br><span class="line">Merged Map outputs&#x3D;0</span><br><span class="line">GC time elapsed (ms)&#x3D;0</span><br></pre></td></tr></table></figure>

<p>如果希望自己实现一个计数器，hadoop 中主要有两种方案：</p>
<p>method 1: 采用 枚举的方式统计计数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">MyCounter</span></span>&#123;MALFORORMED, NORMAL&#125;</span><br><span class="line"><span class="comment">// 对自定义的计数器 +1 操作</span></span><br><span class="line">context.getCounter(MyCounter.MALFORORMED).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>method 2: 采用计数器组、计数器名称的方式进行统计：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.getCounter(<span class="string">&quot;counterGroup_name&quot;</span>, <span class="string">&quot;counter_name&quot;</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>程序执行后，计数器的结果可以在控制台上进行观测。 </p>
<p>参考例子-清理数据：<a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/log">https://github.com/SmallGreens/hadoop_basic/tree/main/src/main/java/log</a></p>
<h1 id="4-Hadoop-数据压缩"><a href="#4-Hadoop-数据压缩" class="headerlink" title="4. Hadoop 数据压缩"></a>4. Hadoop 数据压缩</h1><p><strong>压缩技术</strong> 能够减少底层 HDFS 的读写字节数。压缩提高了网络带宽和磁盘空间的效率。在 Hadoop 中， 压缩可以发生在 MapReduce 的任意阶段（map前，map和 reduce之间，reduce 后）。</p>
<p>虽然采用 压缩技术可以减少磁盘 IO 和网络传输，但同时也增加了 CPU 的运算负担。因此：</p>
<ol>
<li>运算密集型的 job，少用压缩；</li>
<li>IO密集型的job，多用压缩。</li>
</ol>
<h2 id="4-1-压缩方式"><a href="#4-1-压缩方式" class="headerlink" title="4.1 压缩方式"></a>4.1 压缩方式</h2><p>MR 支持的压缩编码包括：DEFLATE, Gzip, bzip2, LZO, Snappy （最后两个不是自带的，需要自行配置安装）。下面对这些压缩方式进行具体的介绍。</p>
<h3 id="Gzip"><a href="#Gzip" class="headerlink" title="Gzip"></a>Gzip</h3><p><strong>优点是</strong>：压缩率比较高，而且压缩和解压速度也比较快。hadoop 本身支持，在应用中处理 Gzip 格式的文件就和直接处理文本一样。并且大部分 Linux 系统都自带 Gzip 命令，使用方便。<strong>缺点</strong>：不支持切片。</p>
<p><strong>应用场景</strong>：当每个文件压缩之后在 130 M 以内（1个块大小内），都可以考虑使用 Gzip 压缩格式。</p>
<h3 id="bzip2"><a href="#bzip2" class="headerlink" title="bzip2"></a>bzip2</h3><p><strong>优点是</strong>：支持 切片，具有很高的压缩率，比 gzip 压缩率高。hadoop 本身自带，使用方便。<strong>缺点</strong>：压缩解压速度慢。</p>
<p><strong>应用场景</strong>：适合对速度要求不高，但需要较高的压缩率的情况；或者输出数据比较大，处理之后 的数据需要的压缩存档以减少磁盘存储空间，并且以后用的比较少的情况。 </p>
<h3 id="Lzo"><a href="#Lzo" class="headerlink" title="Lzo"></a>Lzo</h3><p><strong>优点</strong>：压缩、解压速度比较快，具有合理的压缩率。支持 split，是 hadoop 中 <strong>最流行的压缩格式之一</strong>。可以在 linux 系统下安装 lzop 命令。 <strong>缺点</strong>：压缩率不高，hadoop 本身不支持，需要进行安装；并且 在应用中对 lzo 格式文件需要做一些特殊处理（为了支持 split 需要建索引，还需要指定 InputFormat 为 Lzo 格式）。</p>
<p><strong>应用场景</strong>：一个很大的文本文件，压缩之后还大于 200 M 以上的可以考虑，并且单个文件越大，lzo 优点越明显。</p>
<h3 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h3><p><strong>优点</strong>； 极高速压缩速度，合理的压缩率（即压缩率相对较低）。<strong>缺点</strong>：不支持 split，压缩率比 gzip 低，hadoop 本身不支持，需要安装。</p>
<p><strong>应用场景</strong>：mapreduce 作业的 map 输出的数据比较大的时候，作为 map 到 reduce 的中间数据的压缩格式。</p>
<h2 id="4-2-压缩位置的选择"><a href="#4-2-压缩位置的选择" class="headerlink" title="4.2 压缩位置的选择"></a>4.2 压缩位置的选择</h2><p><strong>Map 输入前采用压缩</strong>： 有大量数据并计划重复处理的情况下，应该考虑对输入进行压缩。在输入阶段，无需显示的指定使用的编码方式，hadoop 会自动检查文件拓展名，如果拓展名能够匹配支持的压缩方式，就会使用对应的编解码器对文件进行处理。</p>
<p><strong>Map 和 reduce 之间进行压缩</strong>: 可以降低网络传输的压力，最常使用。常常使用 LZO 和 Snappy 方法。</p>
<p><strong>Reducer 输出采用压缩</strong>: 在多级 mapreduce 任务中，在此阶段的输出可能会进行压缩。</p>
<h1 id="5-Yarn-资源调度器"><a href="#5-Yarn-资源调度器" class="headerlink" title="5. Yarn 资源调度器"></a>5. Yarn 资源调度器</h1><p>Yarn 是一个资源调度平台，负责为运算程序提供服务运算资源，相当于一个分布式的操作系统平台，而 MapReduce 等运算程序则相当于运行于 该操作系统之上的应用程序。</p>
<h2 id="5-1-组成与运行机制"><a href="#5-1-组成与运行机制" class="headerlink" title="5.1 组成与运行机制"></a>5.1 组成与运行机制</h2><p>Yarn 主要由 ResourceManager(整个集群的老大), NodeManager(管理单个结点的资源), ApplicationMaster(管理每个 job) 和 Container(yarn 上资源的抽象) 等组件构成。如下图所示：</p>
<p><img src="Yarn-workflow.png"></p>
<p>Yarn 通过上述各组件对 MapReduce 程序进行管理，具体的操作流程如下图所示：</p>
<p><img src="Yarn-workflow2.png"></p>
<p>上图中，将一个 MapReduce 的任务分割为了 14 小步，这里可以根据他们</p>
<ol>
<li>申请 运行 ApplicationMaster 并提交相关资源（对应上图中的 0-4 步）：<ol>
<li>MR 程序提交到客户端所在的结点，指定使用 Yarn 运行，会向 ResourceManager 发送一个任务申请；</li>
<li>ResourceManager 返回资源提交路径 <code>hdfs://.../staging</code> 以及 <code>application_id</code>；</li>
<li>客户端提交 job 运行所需的资源（job.split, job.xml, jar 包）到 ResourceManager 指定的提交路径处；</li>
<li>资源提交完毕，申请运行 ApplicationMaster；</li>
</ol>
</li>
<li>将运行 ApplicationMaster 这一任务放入 ResourceManager 管理的任务调度队列，排队执行（步骤5-6）。</li>
<li>ApplicationMaster 的初始化（步骤7-9）：<ol>
<li>创建 container；</li>
<li>下载 任务所需的资源到 ApplicationMaster 所在的 结点；</li>
<li>申请运行 MapTask （申请 MapTask 的容器）；</li>
</ol>
</li>
<li>将 MapTask 的申请放入 ResourceManager 管理的任务调度队列中，排队执行（步骤9-10）。</li>
<li>执行 MapTask（步骤10-11）:<ol>
<li>ResourceManager 为 MapTask 分配执行的 container；</li>
<li>ApplicationMaster 向 MapTask 所在的 container 发送任务启动脚本。</li>
</ol>
</li>
<li>将 Reduceask 的申请放入 ResourceManager 管理的任务调度队列中，排队执行（步骤12）。</li>
<li>执行 ReduceTask：分配得到的 ReduceTask container 从 map task 处获得分区数据，并执行 Reduce（步骤13）。</li>
<li>程序执行完毕，向 ResourceManager 注销自己。</li>
</ol>
<p>除了上述的任务管理功能外，Yarn 还会监控任务执行的进度情况，并可以定时向 任务所有者（客户端）报告任务的进度。</p>
<h2 id="5-2-资源调度器"><a href="#5-2-资源调度器" class="headerlink" title="5.2 资源调度器"></a>5.2 资源调度器</h2><p>Hadoop 作业调度器主要有三种：<strong>FIFO</strong>，<strong>Capacity Scheduler</strong>，<strong>Fair Scheduler</strong>， 其中 Hadoop2 默认的资源调度器为 <strong>Capacity scheduler</strong>。</p>
<p><strong>FIFO</strong>：先进先出。维护一个队列放置 task，当新的服务器结点有资源，则将队列中的第一个 task 交给对应结点（注意这个task 可能是 初始化 ApplicationMaster or MapTask or ReduceTask）。</p>
<p><strong>Capacity Scheduler</strong>：支持多个 FIFO 队列，每个队列可配置一定的资源量，每个队列采用 FIFO 调度策略。因为有多个队列，添加任务的时候会 <strong>首先添加到最闲的队列中</strong>（根据队列中的任务数与其应该分得的计算资源之间的比值进行判定）。</p>
<p>此外，为了防止同一个用户的作业独占队列中的资源，该调度器会对 <strong>同一用户提交的作业所占资源量进行限制</strong>。</p>
<p>相对于 FIFO 调度策略，<strong>Capacity Scheduler</strong> 具有更高的并发度。</p>
<p><strong>Fair Scheduler</strong>：同样使用多队列。每个队列中的 job 会按照 <strong>优先级分配资源</strong>，优先级越高资源分配越多，但是每个 job 都会分配到一定资源。</p>
<p>此外，job 按照 <strong>缺额进行排序</strong>（所谓缺额是指job实际需要的资源与被分配到的资源之间的差距）， job 缺额越大，越先获得资源有限执行。</p>
<p>相比上述两种调度器， Fair Scheduler 的并发度最高。 </p>
<h2 id="5-3-推测执行"><a href="#5-3-推测执行" class="headerlink" title="5.3 推测执行"></a>5.3 推测执行</h2><p>由于实际作业完成时间总是取决于 <strong>执行最慢的任务的完成时间</strong>。一个 job 通常有多个 task 组成，但由于执行 task 的各个机器性能不同，性能最慢的机器会影响系统整体的速度（例如 map 阶段，一两个机器运行很慢，就会一直卡住无法进入reduce 阶段）。</p>
<p>因此，Yarn 在资源调度时 提供了一种 <strong>推测执行机制</strong>。即当发现拖后腿的任务时，系统会为其启动一个备份任务，同时运行，最后谁先运行完毕，就采用谁的结果。开启推测执行参数在 <code>mapred-site.xml</code> 中设置，默认设置为开启。</p>
<p><strong>推测执行算法原理</strong>：MR 会根据当前任务的执行进度（progress - 百分比）以及到现在为止的任务执行时间推断出 <strong>当前任务执行结束的时刻</strong>。同时，根据计算任务运行的平均时间，计算如果当前时刻开始新建备份任务的话，<strong>备份任务推测完成时刻</strong>。比较上述两个时刻求得 <strong>差值</strong>。最后选择差值最大的任务为其启动备份任务。</p>
<p>推测执行机制 是一种典型的 <strong>以空间换时间</strong> 的优化模式。但在资源紧缺的情况下，应合理使用该机制。</p>
<p>具体地，为了更好的应用 该机制，需要关注下述几点：</p>
<ol>
<li>每个 task 只能有一个备份任务；</li>
<li>为了防止大量任务同时启动备份任务造成资源浪费，MR 为每个job 设置了同时启动备份任务数目上限；</li>
<li>只有当前 job 已完成的 task 超过 5% 才允许 启动备份任务；</li>
<li>当任务间存在严重的负载倾斜，以及特殊的任务（例如任务向数据库中写数据）不应该使用推测执行机制。</li>
</ol>
<h1 id="6-Hadoop优化"><a href="#6-Hadoop优化" class="headerlink" title="6. Hadoop优化"></a>6. Hadoop优化</h1><p>MapReduce 程序效率的瓶颈主要可以分为两点：</p>
<ol>
<li>计算机性能：CPU，内存，磁盘健康，网络等。这部分可以通过硬件更新来提升。当然，对于编程来讲，可能需要调节相关的参数来适应相应的硬件水平。</li>
<li>I/O 操作优化，常见的一些问题如下：<ol>
<li>数据倾斜；</li>
<li>map 和 reduce 数设置不合理；map运行时间太长，导致 reduce 等待过久；</li>
<li>小文件过多 或者有 大量的不可分块的超大文件；</li>
<li>spill 次数过多，merge 次数过多。</li>
</ol>
</li>
</ol>
<p>针对上述的问题，我们可以从数据输入的不同阶段出发，在每个阶段提供一些优化的思路，如下：</p>
<ol>
<li><strong>数据输入阶段</strong>：<ol>
<li>大量的小文件可能导致 map 任务过多，增大 map 任务的装载次数，而任务装载比较耗时，从而导致 MR 运行较慢。可使用 CombineTextInputFormat 作为输入，将小文件合并。</li>
</ol>
</li>
<li><strong>map阶段</strong>：<ol>
<li>减少 spill 次数，可以调整 <code>io.sort.mb</code> 及 <code>sort.spill.percent</code> 参数，增大触发 spill 的内存上限，减少 spill 次数，从而减少磁盘 IO；</li>
<li>减少 merge 次数：通过调整 <code>io.sort.factor</code> 参数，增大 merge 文件数目，减少 merge 次数，从而缩短 MR 处理时间；</li>
<li>map 之后，在不影响业务逻辑的前提下，先进行 combine 处理，减少网络 IO；</li>
</ol>
</li>
<li><strong>I/O 传输阶段</strong>：<ol>
<li>采用数据压缩方式，减少网络 IO 时间，安装 snappy 和 LZO 压缩编码器；</li>
<li>使用 SequenceFile 二进制格式（一种比较紧凑的数据格式）；</li>
</ol>
</li>
<li><strong>reduce阶段</strong>：<ol>
<li>合理设置 reduce 数：太少导致 task 等待，延长处理时间；太多，导致 map、reduce 任务间竞争资源，造成处理超时等错误；</li>
<li>设置 map reduce 共存：调整 <code>slowstart.completedmaps</code> 参数，使 map 运行到一定程度后，reduce 也开始运行，减少 reduce 的等待时间；</li>
<li>允许的情况下，规避使用 reduce： 因为 reduce 在用于连接数据集的时候会产生大量的网络消耗；</li>
<li>合理设置 reduce 端的 buffer：可以设置部分内存读 buffer 中的数据 直接拿给 reduce 使用，可通过设置 <code>mapred.job.reduce.input.buffer.percent</code> 来实现。</li>
</ol>
</li>
</ol>
<p>除了上述4个阶段的优化策略，针对特别的问题 <strong>数据倾斜</strong>（现象是某一区域的数据量要远远大于其他区域） 我们可以采用下面的一些思路进行优化处理：</p>
<ol>
<li>抽样和范围分区，通过对原始数据进行抽样得到的结果集来预设分区边界值；</li>
<li>自定义分区，依据对数据的了解，对数据进行自定义分区；</li>
<li>使用 combiner；</li>
<li>采用 map join，尽量避免 reduce join。</li>
</ol>
<p><strong>HDFS小文件问题</strong> 也是一个重要的需要优化的对象。因为每个小文件都需要在 namenode 上建立索引，而一个索引固定占用 150 bytes，当小文件过多，大量占用 namenode 中的索引空间，会降低文件搜索速度。针对这一问题，有下列几种处理方案：</p>
<ol>
<li>hadoop archive: 是一个高效地将小文件放入 hdfs 块中的文件存档工具，它能够将多个小文件打包成一个 HAR 文件，这样就减少了 NameNode 的内存使用；</li>
<li>Sequence File: 由一系列二进制 key/value 组成，如果 key 为文件名，value 为文件内容，则可以将大批小文件合并成一个大文件；</li>
<li>CombineFileInputFormat: 是一种新的 InputFormat，用于将多个文件合并成一个单独的 split，另外，他会考虑数据的存储位置；</li>
<li>开启 JVM 重用：对于大量小文件的job，可以开启 JVM 重用，原理是一个 map 运行在一个 JVM 上进程上，开启重用的话，该 JVM 进程运行完毕当前 map 后可以继续服务其他 map。</li>
</ol>
<p>最后，总结一些常用的优化参数如下：</p>
<ol>
<li><code>mapreduce.map.memory.mb</code>: 规定一个mapTask 可以使用的内存资源上限；</li>
<li><code>mapreduce.reduce.memory.mb</code>: 规定一个 reduceTask 可以使用的内存资源上限；</li>
<li>规定 MapReduce 计算过程中的资源使用情况：例如，可以通过参数指定各阶段使用 cpu 数；reduce 去 map 中取数据的并行数；数据溢写阈值；</li>
<li>YARN 相关参数：给应用程序 container 分配的最大最小的内存，cpu核数等；</li>
<li>shuffle 性能优化：环形缓冲区大小，环形缓冲区溢出比例。</li>
<li>容错相关参数：maptask 最大尝试次数；task timeout 等。</li>
</ol>
<p><strong>参考</strong></p>
<ol>
<li>尚硅谷Hadoop 2.x教程(hadoop框架精讲)：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cW411r7c5">https://www.bilibili.com/video/BV1cW411r7c5</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/09/BigData/HDFS_conclu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/09/BigData/HDFS_conclu/" class="post-title-link" itemprop="url">HDFS-hadoop的文件系统</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-04-09 15:18:28 / 修改时间：17:12:27" itemprop="dateCreated datePublished" datetime="2021-04-09T15:18:28+08:00">2021-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>hadoop 的文件存储系统成为 hdfs(hadoop distributed file system)， 它用于解决大数据的存储问题，可以管理 分布在多台服务器中数据。 </p>
<p>它具有如下的 <strong>优缺点</strong>：</p>
<p>优点：</p>
<ul>
<li>多副本存储文件，具有高容错性；</li>
<li>分布式存储，适合处理大数据， 并且可将集群构建在廉价机器上。</li>
</ul>
<p>缺点：</p>
<ul>
<li>不适合低延迟的数据访问；</li>
<li>无法高效的对大量小文件进行存储（占用 NameNode 大量的内存来存储文件目录和块信息，并且小文件存储的寻址时间会超过读取时间，违反了 hdfs 的设计目标）；</li>
<li>不支持并发写入，文件随机修改。</li>
</ul>
<p>HDFS主要由下面几个部分 <strong>组成</strong>：</p>
<ul>
<li>NameNode: 充当整个集群文件系统的目录功能，存储 文件的元数据信息(metadata, 包括文件名，副本数，权限等)。此外，它还作为整个集群文件的管理者， 管理数据块的映射信息， 处理来自客户端 的读写请求等。</li>
<li>Secondary NameNode: 它并非 NameNode 的热备（就是说 NameNode 如果挂掉，它并不能马上替换 NameNode 并提供服务）。它的主要工作是辅助 NameNode的工作，包括定期合并 <code>Fsimage</code> 和 <code>Edits</code> 文件，并推送给 NameNode。在紧急情况下，可用于恢复部分 NameNode 内容。</li>
<li>DataNode: 负责实际的数据存储。</li>
<li>Client: 可请求数据读写。</li>
</ul>
<p>HDFS 数据 <strong>存储块的大小</strong> 默认为 128 M(源码中在 <code>hdfs-default.xml</code> 文件中通过参数 <code>dfs.blocksize</code>)，该值主要取决于 系统磁盘读写的速率。</p>
<p>一般地认为，寻址时间为传输时间 1% 为最佳状态，如寻址时间约为 10ms，则可计算出最佳的传输时间为约 1s。若当前磁盘传输速率普遍为 100 MB/s，一个块文件需要一次寻址，则可获得 HDFS 块的推荐大小：<code>1s * 100MB/s = 100 MB</code>，近似为 128 M。所以，如果磁盘读写速度快（如 SSD），则推荐使用更大的 HDFS 块大小。</p>
<h1 id="2-HDFS的数据读写"><a href="#2-HDFS的数据读写" class="headerlink" title="2. HDFS的数据读写"></a>2. HDFS的数据读写</h1><h2 id="2-1-shell-操作"><a href="#2-1-shell-操作" class="headerlink" title="2.1 shell 操作"></a>2.1 shell 操作</h2><p>HDFS 提供相关的指令对 文件系统中的文件进行管理（如上传、下载、删除等）。具体可以使用 <code>bin/hadoop fs 具体命令</code> or <code>bin/hdfs dfs 具体命令</code>，这两个指令差不多， <code>hadoop fs</code> 相当于是 <code>hdfs dfs</code> 的 “父类”。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -help rm # 查询 rm 指令的功能</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /  # 查看根目录下的内容</span><br><span class="line">hadoop fs -lsr /  # 递归显示 根目录下的内容</span><br><span class="line">hadoop fs -mkdir -p /user/lab1  # 穿件目录，创建多级目录需要 添加 -p</span><br><span class="line">hadoop fs -moveFromLocal $&#123;本地文件&#125; $&#123;hdfs目录&#125;   # 剪切文件</span><br><span class="line">hadoop fs -copyFromLocal $&#123;本地文件&#125; $&#123;hdfs目录&#125;   # 复制文件 -- 或者使用 -put</span><br><span class="line">hadoop fs -copyToLocal $&#123;hdfs文件&#125; $&#123;本地目录&#125;      # 从 hdfs 中下载文件到本地，或者使用 -get</span><br><span class="line">hadoop fs -appendToFile $&#123;追加的文件&#125; $&#123;hdfs中的文件目录&#125;</span><br><span class="line"></span><br><span class="line">hadoop fs -chgrp $&#123;组名&#125;   # 修改组</span><br><span class="line"></span><br><span class="line">hadoop fs -cp $&#123;hdfs中原文件&#125; $&#123;hdfs中目的地址&#125;  # 拷贝</span><br><span class="line">hadoop fs -mv $&#123;hdfs中原文件&#125; $&#123;hdfs中目的地址&#125;  # 剪切</span><br><span class="line">hadoop fs -getmerge $&#123;待合并的文件内容&#125; $&#123;合并后的文件名&#125;  # 合并文件</span><br><span class="line"></span><br><span class="line">hadoop fs -tail $&#123;文件名&#125;  # 查看文件的最后一些行 -- log 文件常常以追加的形式更新，所以这个很常用</span><br><span class="line">hadoop fs -rm $&#123;文件名/文件夹&#125;  # 删除文件、文件夹， -R 参数，递归删除。</span><br><span class="line">hadoop fs -du $&#123;目录&#125;       # 查询对应目录的内容的大小，添加 -h 参数，添加单位例如 M；-s 参数，统计整个文件夹总大小</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 副本设置</span></span><br><span class="line">hadoop fs -setrep $&#123;副本数&#125; $&#123;文件名&#125;</span><br></pre></td></tr></table></figure>

<p>整体来说，hdfs 的操作指令与 linux 文件的操作非常类似。</p>
<h1 id="2-2-客户端操作"><a href="#2-2-客户端操作" class="headerlink" title="2.2 客户端操作"></a>2.2 客户端操作</h1><p>可以在 windows 上建立客户端，然后通过 java 程序来操作 hdfs 的文件。首先需要在 windows 上搭建 hadoop 环境，参考 <a target="_blank" rel="noopener" href="https://smallgreens.github.io/2021/02/02/BigData/InstallOnWindows/">link</a>。</p>
<p>配置完毕后，可以使用 intellij 新建一个 maven 工程，具体可以参考 github 中的 <a target="_blank" rel="noopener" href="https://github.com/SmallGreens/hadoop_basic/blob/main/src/main/java/HDFSClient.java">代码</a>。</p>
<p>使用客户端可以进行对 hdfs 进行读写。其中 <strong>写数据</strong> 步骤如下：</p>
<ol>
<li>客户端创建 distributed <code>FileSystem</code> 对象（含有上传到 hdfs 系统中的路径信息），向 <strong>NameNode</strong> 所在的服务器发送上传请求；</li>
<li>NameNode 检查文件路径等信息，进行一些检查：例如文件是否存在，路径是否合法等。检查完毕后响应客户端的请求；</li>
<li>客户端得到可以上传的响应信息后，请求上传第一个 block；</li>
<li>NameNode 收到该请求后进行分析，返回给客户端上传数据的 <strong>DataNode</strong>，e.g. dn1, dn2, dn3。数据结点的确定主要根据<strong>两个因素</strong>：1. 距离近的有限上传；2. 负载轻的优先上传；</li>
<li>客户端生成输出流 <code>FSDataOutputStream</code>，向对应的 DataNode 请求建立 block 的传输通道；</li>
<li>DataNode 应答成功，客户端进行数据传输（一个个的 packets）；</li>
<li>DataNode 服务器中首先将数据放置在内存中，一边序列化到本地硬盘，一边传输到下个结点的内存中。</li>
</ol>
<p>在上面的第四步中，NameNode 需要寻找存储数据的结点，这一结点的确定遵循距离最近的原则，即上传数据的结点与存储数据的结点距离尽可能近。这里，就需要定义 <strong>结点距离</strong>：为两个结点到达最近的公共祖先的距离总和。例如：</p>
<ul>
<li>同一结点上的进程：距离 = 0；</li>
<li>同一机架上的不同结点（共一个端结点）：距离 = 2；</li>
<li>同一数据中心不同机架上的结点（同一数据中心的机架端结点接到同一个数据中心结点上）：距离 = 4。</li>
</ul>
<p>除了上述的距离最近原则，具体存储数据时 hadoop 还需考虑数据的安全可靠。对于常见的 3副本设置（<a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication">参考官网</a>），数据的放置一般首先放置在某一随机的结点（尽量考虑距离近，负载均衡），然后第二个副本放置在同一机架的不同 结点上，而第三个副本则放置在不同的机架上（为了<strong>安全可靠性</strong>）。</p>
<p>类似于写数据，<strong>读数据</strong>也需要客户端首先与 NameNode 进行通讯，然后再从具体的 DataNode 上读取数据。步骤如下：</p>
<ol>
<li>客户端创建 distributed <code>FileSystem</code> 对象（包含 hdfs 文件目录信息），向 NameNode 发送下载请求；</li>
<li>NameNode 返回目标文件的元数据，客户端获得数据存在的 DataNode 位置；</li>
<li>客户端创建 <code>FSDataInputStream</code> 对象，并逐块向对应的 DataNode 结点请求数据（如果多块文件在同一个服务器上，可以一次性返回）；</li>
<li>获取完毕数据后本地拼接为完整文件。</li>
</ol>
<h1 id="3-文件索引系统"><a href="#3-文件索引系统" class="headerlink" title="3. 文件索引系统"></a>3. 文件索引系统</h1><p><strong>NameNode</strong> 和 <strong>SecondaryNameNode</strong> 共同构成了 HDFS 的文件索引、管理系统。这里对他们的工作机制进行详细的介绍。</p>
<h2 id="3-1-NameNode工作机制"><a href="#3-1-NameNode工作机制" class="headerlink" title="3.1 NameNode工作机制"></a>3.1 NameNode工作机制</h2><p>在运行的 HDFS 系统中，NameNode 为实现运行的高效，总是在内存中运行。但内存具有掉电丢失的特点，为了保证数据的可靠性，HDFS 会在在磁盘中使用 <code>FsImage</code> 备份元数据（所谓元数据就是文件属性信息，比如修改日期，权限等）。</p>
<p>但频繁操作存储于磁盘中的数据，会降低系统性能。因此，为减少 <code>FsImage</code> 的修改，当需要更新 元数据时，会 <strong>首先</strong> 将更新的内容记录到 <code>Edits</code> 文件（也在磁盘中，但只进行追加操作，效率非常高），然后 再在 内存中更新（安全性）。</p>
<p>当 <code>NameNode</code> 服务器上电时，它将编辑日志（<code>edits_inprogress_xxx</code>）和 镜像文件(<code>Fsimage</code>) 加载到内存中，进行合并，恢复出整个集群的元数据信息 (通常内存至少128 G, 每个 block 占 150 bytes)。</p>
<h2 id="3-2-SecondaryNameNode工作机制"><a href="#3-2-SecondaryNameNode工作机制" class="headerlink" title="3.2 SecondaryNameNode工作机制"></a>3.2 SecondaryNameNode工作机制</h2><p>由于 <code>Edits</code>文件 不能无限扩大，再它达到一定大小时，需要与 <code>FsImage</code> 文件进行合并。HDFS 使用 SecondaryNameNode，来实现这一功能。具体地，在 SecondaryNameNode 中，会按顺序执行下列操作：</p>
<ol>
<li>请求询问 NameNode 是否需要进行 checkpoint 操作 （即日志和镜像文件合并），当下列两个任一个满足时，会触发 checkpoint：<ol>
<li>定时时间到（默认是1小时，<code>hdfs-site.xml</code> 中配置 property <code>dfs.NameNode.checkpoint.period</code> 修改）</li>
<li>Edits 中的数据条数超过阈值（以轮询方式查询，默认每隔1分钟轮询一次，默认阈值是100万条，<code>hdfs-site.xml</code> 中， <code>dfs.NameNode.checkpoint.txns</code> 配置阈值， <code>dfs.NameNode.checkpoint.check.period</code> 配置轮询时间间隔）；</li>
</ol>
</li>
<li>如果需要 checkpoint 操作，首先将 NameNode 中的 <code>edit_inprogress_001</code> 文件滚动为 <code>edits_001</code> 并同时生成 空的 <code>edit_inprogress_002</code> 文件，后序修改记录将会添加到 <code>edit_inprogress_002</code> 中。</li>
<li>然后将 <code>edit_001</code> 和 <code>FsImage</code> 文件拷贝到 SecondaryNameNode 中，SecondaryNameNode 在内存中将上述两者进行合并，生成新的 <code>FsImage</code> 文件。</li>
<li>最后将合并生成的新的 <code>FsImage</code> 文件拷贝回 NameNode 中，替换旧的 <code>Fsimage</code> 文件。</li>
</ol>
<h2 id="3-3-Edit、FsImage-文件"><a href="#3-3-Edit、FsImage-文件" class="headerlink" title="3.3 Edit、FsImage 文件"></a>3.3 Edit、FsImage 文件</h2><p>在 NameNode 服务器上，<code>Edit</code> 和 <code>FsImage</code> 文件在 目录 <code>hadoop-2.8.3/data/tmp/dfs/name/current</code> 中。可以使用 <code>hdfs oiv -p XML -i &lt;要转换的fsimage 文件名&gt; -o &lt;输出的文件名.xml&gt;</code> 将 FsImage 转为 xml 文件进行展示。可以看到，在 fsimage 文件中，存放了文件的 <strong>文件名</strong>，<strong>路径</strong>，<strong>副本数</strong>，<strong>权限</strong>，<strong>创建时间</strong> 等 meta 信息。类似的，可以使用 <code>hdfs oev -p XML -i &lt;要转换的 edits 文件&gt; -o &lt;输出的文件名.xml&gt;</code> 将 <code>Edits</code> 文件转为 xml 格式进行查看。</p>
<p>需要注意的是，<code>FsImage</code> 文件和 <code>Edits</code> 文件 并没有记录 块所对应的 DataNode。在 HDFS 中，这一信息 （DataNode 上的数据块信息） 将会在在集群启动后 由各个 <strong>DataNode</strong> 进行 <strong>动态上报</strong>。具体地，在集群启动时，所有 DataNode 会上报一次他们所持有的数据块信息，然后，后序每隔一段时间 DataNode 会再进行上报。这么做是因为数据块的位置信息可能会因为 DataNode 的状态而变化，因此使用动态的方式获取，保证数据位置信息的准确性和实时性。</p>
<h2 id="3-4-集群的安全模式"><a href="#3-4-集群的安全模式" class="headerlink" title="3.4 集群的安全模式"></a>3.4 集群的安全模式</h2><p>根据上述的介绍，我们知道了 HDFS 文件索引系统保存更新索引的方式。在这样的机制下，HDFS 系统在 NameNode 启动时，会有一段特殊的安全模式期。</p>
<p>所谓的 <strong>安全模式</strong> 是指 NameNode 文件索引系统对于客户端来说是只读的，不允许执行写操作。当 HDFS 系统启动，便处于安全模式。</p>
<p><strong>NameNode</strong> 首先将镜像文件 <code>FsImage</code> 载入内存，并执行编辑日志（<code>Edits</code>） 中的各项操作。合并完成后，创建一个新的 <code>FsImage</code> 文件和一个空的 编辑日志放回磁盘，同时，NameNode 会开始监听 DataNode 的请求。</p>
<p>对于各个 <strong>DataNode</strong>，他们以块列表的形式记录 各个存储在它们上的数据块。在系统正常操作期间， NameNode 会在内存中保留所有块的位置映射信息。但在 DataNode 和 NameNode 启动时，需由 DataNode 向 NameNode 发送最新的块列表信息。</p>
<p>最后，当 NameNode 完成 FsImage 的 <strong>合并操作</strong>，并且接收到 <strong>足够多的块位置信息</strong> 后，才会退出安全模式（达到最小副本条件后30s 退出安全模式）。</p>
<p>所谓 <strong>最小副本条件</strong> 是指： 整个文件系统中 99.9% 的块满足最小副本级别的要求（默认值：<code>dfs.replication.min=1</code>）。</p>
<p>最后，在刚刚格式化一个 hdfs 集群的时候，由于系统中还没有任何块，NameNode 不会进入安全模式。</p>
<h1 id="4-数据结点"><a href="#4-数据结点" class="headerlink" title="4. 数据结点"></a>4. 数据结点</h1><p>DataNode 中存放一个个的 blocks, 数据 block 的内容包括：数据，数据长度，校验和，时间戳。通过上面对 NameNode 的介绍，我们知道数据的存储信息仅放置在 NameNode 内存中（即不做持久化处理），需要 DataNode 进行动态的上报、更新。</p>
<p>具体的，块信息分为 <strong>启动时</strong> 上报和 <strong>运行中</strong> 的上报。启动时，DataNode 启动后向 NameNode 注册，报告其中的块信息，注册成功后，NameNode 向 DataNode 返回注册成功信息。运行中， DataNode 会每隔固定时间（1小时）上报一次所有块信息。</p>
<h2 id="4-1-可用性判断"><a href="#4-1-可用性判断" class="headerlink" title="4.1 可用性判断"></a>4.1 可用性判断</h2><p>除了数据块信息的上报，NameNode 需要知道 DataNode 的 <strong>可用性</strong>，即判断相关的 DataNode 网络是否顺畅连通，硬件是否运行正常。这一目标由 DataNode 和 NameNode 之间保持的 <strong>心跳通讯</strong> 来实现。DataNode 心跳每3秒1次，心跳返回结果带有 NameNode 给该 DataNode 的命令。</p>
<p>通常，如果超过 10 分钟（+30s）没有收到 DataNode 的心跳，NameNode 会认为该结点不可用，从而以后不会再向该 DataNode 中存放任何内容。</p>
<p>上述的 DataNode 的延迟下线时间称为 <strong>超时时长</strong>。hdfs 默认的超时时长 10分钟 + 30 秒 通过公式 <code>timeout = 2 * dfs.NameNode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval</code> 计算。其中 <code>dfs.NameNode.heartbeat.recheck-interval</code> 默认值为 5分钟（300’00 ms），<code>dfs.heartbeat.interval</code> 默认值为 3秒。</p>
<h2 id="4-2-服役新节点、退役结点"><a href="#4-2-服役新节点、退役结点" class="headerlink" title="4.2 服役新节点、退役结点"></a>4.2 服役新节点、退役结点</h2><p>如果想向集群中添加新的 datanode，只需要镜像集群中的一台 datanode 机器，修改 ip 和主机名称，并删除其中的旧数据 和 旧 logs: <code>rm -rf /data /logs</code>。最后在新的结点上单独启动 DataNode 以及 nodemanager，即可自动并入集群中。</p>
<p>如果想提升安全性，仅让有权限的机器加入到集群中，可以使用 <strong>“白名单”</strong> 功能（<code>hdfs-site.xml</code> 中添加 <code>dfs.hosts</code> 属性）。此外，还可以使用黑名单方式，强制集群中的某些服务器退出（退出结点上的内容会被拷贝到其他节点上）。</p>
<h1 id="5-其他"><a href="#5-其他" class="headerlink" title="5. 其他"></a>5. 其他</h1><h2 id="5-1-存档文件"><a href="#5-1-存档文件" class="headerlink" title="5.1 存档文件"></a>5.1 存档文件</h2><p>小文件会影响 hdfs 系统的性能。因为每个小文件都占用一个文件块，而每个文件块都需要在 NameNode 中占有一条记录，故每个小文件都会占用 150 字节的记录空间（注意：不影响DataNode，数据实际存储空间仍是文件大小）。因此，有大量小文件时，会大量占用 NameNode 中的索引资源。</p>
<p>一种处理方案是 使用 hdfs 存档文件 或称 har 文件。原理上，hdfs 存档文件对内是一个个独立文件，但是对 NameNode 而言却是一个整体，因为减少了在 NameNode 中内存的占用。 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archivename &lt;归档后的名字-.har 结尾&gt; -p &lt;src文件的路径&gt; &lt;输出文件的路径&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以查看 har 存档文件，相当于一个单独的文件系统</span></span><br><span class="line">hadoop fs -ls -R har://&lt;har 文件路径&gt; </span><br></pre></td></tr></table></figure>

<h2 id="5-2-快照管理"><a href="#5-2-快照管理" class="headerlink" title="5.2 快照管理"></a>5.2 快照管理</h2><p>HDFS 支持快照备份。但 HDFS 快照并不会立即复制所有的文件，在产生快照时，仅对目录做一个复制备份，只有当后序有写入、修改发生时，才会产生新的文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开启指定目录的快照功能</span></span><br><span class="line">hdfs dfsadmin -allowSnapshot &lt;路径&gt;  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 对目录创建快照</span></span><br><span class="line">hdfs dfs -createSnapshot &lt;路径&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 比较两个快照目录的不同之处  </span></span><br><span class="line">hdfs snapshotDiff &lt;路径1&gt; &lt;路径2&gt;  </span><br></pre></td></tr></table></figure>

<p><strong>参考</strong></p>
<ol>
<li>尚硅谷Hadoop 2.x教程(hadoop框架精讲)：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cW411r7c5">https://www.bilibili.com/video/BV1cW411r7c5</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/31/Database/B_tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/31/Database/B_tree/" class="post-title-link" itemprop="url">数据库索引方式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-03-31 11:18:28 / 修改时间：22:31:58" itemprop="dateCreated datePublished" datetime="2021-03-31T11:18:28+08:00">2021-03-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>MySQL 数据库底层使用 B+树完成数据的索引，本篇文章，将对B树的基础知识，以及实际数据库引擎的索引方式进行简单介绍。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/03/31/Database/B_tree/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/BigData/distrib_script/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/BigData/distrib_script/" class="post-title-link" itemprop="url">linux文件分发工具</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-03-01 17:18:28 / 修改时间：21:03:04" itemprop="dateCreated datePublished" datetime="2021-03-01T17:18:28+08:00">2021-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 hadoop 集群操作中，经常需要在集群中的机器之间进行文件的拷贝，文件的同步等 工作。linux 中通过下面的一些指令、方法来实现这一功能。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/03/01/BigData/distrib_script/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/BigData/hadoop_configuration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/BigData/hadoop_configuration/" class="post-title-link" itemprop="url">hadoop集群配置</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-03-01 15:18:28 / 修改时间：21:12:38" itemprop="dateCreated datePublished" datetime="2021-03-01T15:18:28+08:00">2021-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文对 hadoop 的基础背景知识 以及 hadoop集群的安装、基础配置进行了总结。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/03/01/BigData/hadoop_configuration/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/Algorithm/Bottom_up_binaryTree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/Algorithm/Bottom_up_binaryTree/" class="post-title-link" itemprop="url">后序遍历-自底向上的思想</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-03-01 11:20:25 / 修改时间：21:11:47" itemprop="dateCreated datePublished" datetime="2021-03-01T11:20:25+08:00">2021-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">数据结构与算法</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在二叉树类型的问题中，常常求解最大和、最长路径等的问题，可以按照自底向上的思路进行处理，也就是说，从树的底部开始分析，将可能的最大结果一步一步地向上汇总，直到抵达树的根部。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/03/01/Algorithm/Bottom_up_binaryTree/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/05/Algorithm/TraverseTree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/05/Algorithm/TraverseTree/" class="post-title-link" itemprop="url">非递归方法遍历二叉树</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-02-05 12:18:28" itemprop="dateCreated datePublished" datetime="2021-02-05T12:18:28+08:00">2021-02-05</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-03-30 22:57:09" itemprop="dateModified" datetime="2021-03-30T22:57:09+08:00">2021-03-30</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">数据结构与算法</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>二叉树遍历是经典的算法题目，最传统的方案是使用递归的方式进行遍历，特点是代码非常简洁。当然，除了递归方案，二叉树也可以使用 迭代的方法进行遍历。具体的，包括两种思路，一种是使用程序栈模拟递归过程，第二种是利用叶子结点 的 null 子节点模拟线索二叉树完成遍历（Morries 方法）。本文将对他们进行总结归纳。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/02/05/Algorithm/TraverseTree/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/02/BigData/InstallOnWindows/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/02/BigData/InstallOnWindows/" class="post-title-link" itemprop="url">Windows上安装Hadoop</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-02-02 12:18:28" itemprop="dateCreated datePublished" datetime="2021-02-02T12:18:28+08:00">2021-02-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-02-03 22:08:57" itemprop="dateModified" datetime="2021-02-03T22:08:57+08:00">2021-02-03</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>为了测试方便，在 windows 上安装了 hadoop。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/02/02/BigData/InstallOnWindows/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/30/Java/HashAlgorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/30/Java/HashAlgorithm/" class="post-title-link" itemprop="url">Java HashMap 的实现分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-01-30 09:06:25" itemprop="dateCreated datePublished" datetime="2021-01-30T09:06:25+08:00">2021-01-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-03-30 22:57:56" itemprop="dateModified" datetime="2021-03-30T22:57:56+08:00">2021-03-30</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 Java 中，<code>Map</code> 和 <code>Set</code> 接口，最常用的实现类分别为 <code>HashMap</code> 和 <code>HashSet</code>， 而 <code>HashSet</code> 的背后实际上就是 HashMap。 因此， 为探究 Java 实现 Hash 集合类的方法，在这里对 Java <code>HashMap</code> 的源码进行简单的分析。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/01/30/Java/HashAlgorithm/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/28/Java/StringAndStrBuilder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Matt Yin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ha$p^3$lanet">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/28/Java/StringAndStrBuilder/" class="post-title-link" itemprop="url">String 和 StringBuilder 的区别分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-01-28 09:06:25" itemprop="dateCreated datePublished" datetime="2021-01-28T09:06:25+08:00">2021-01-28</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-02-05 22:40:59" itemprop="dateModified" datetime="2021-02-05T22:40:59+08:00">2021-02-05</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">1- 编程相关</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Java 提供了3个常用的用于表示字符串的类，分别为 <code>String</code>，<code>StringBuilder</code>， <code>StringBuffer</code>。本篇文章对他们的差异进行简单的分析。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/01/28/Java/StringAndStrBuilder/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Matt Yin</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments('#valine-comments', () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', () => {
    new Valine(Object.assign({"enable":true,"appId":"k2sEIOb3zYiWCB2PDVhHsp1y-MdYXbMMI","appKey":"kgxrBrtFbe83dXfCFnYkplkY","serverURLs":null,"placeholder":"欢迎留言~","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":false,"comment_count":false,"recordIP":false,"enableQQ":false,"requiredFields":[]}, {
      el: '#valine-comments',
      path: "/",
      serverURLs: "https://k2seiob3.api.lncldglobal.com"
    }));
  }, window.Valine);
});
</script>

</body>
</html>
